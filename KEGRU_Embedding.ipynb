{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KEGRU_Embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0AGxRdas3o6U",
        "colab_type": "code",
        "outputId": "f00ae6f6-4968-46b0-8492-a24ba8915c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c72e000 @  0x7f111b2142a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X9YqKDFG3t-j",
        "colab_type": "code",
        "outputId": "12969a2c-3d31-404e-eaab-625ed591f984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z1DJ82V83uBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import math \n",
        "import random\n",
        "import gzip\n",
        "from scipy.stats import bernoulli\n",
        "import torch\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqR0IoUq3uGJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nummotif=16 #number of motifs to discover\n",
        "bases='ACGT' #DNA bases\n",
        "# basesRNA='ACGU'#RNA bases\n",
        "batch_size=200 #fixed batch size "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LpKfpmpz3uJD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dinucshuffle(sequence):\n",
        "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
        "    random.shuffle(b)\n",
        "    d=''.join([str(x) for x in b])\n",
        "    return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ekjz6q8W3uLr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Chip():\n",
        "    def __init__(self,filename):\n",
        "        self.file = filename\n",
        "            \n",
        "    def openFile(self):\n",
        "        data_all=[]\n",
        "        pos_data=[]\n",
        "\n",
        "        with gzip.open(self.file, 'rt') as data:\n",
        "            next(data)\n",
        "            reader = csv.reader(data,delimiter='\\t')\n",
        "\n",
        "            for row in reader:\n",
        "\n",
        "                ## When using Embedding\n",
        "                pos_data.append(row[2])\n",
        "                data_all.append([row[2],[1]])\n",
        "                data_all.append([dinucshuffle(row[2]),[0]])\n",
        "\n",
        "\n",
        "#         random.shuffle(train_dataset)\n",
        "        train_dataset=data_all\n",
        "\n",
        "        size=int(len(train_dataset)/3)\n",
        "        firstvalid=train_dataset[:size]\n",
        "        secondvalid=train_dataset[size:size+size]\n",
        "        thirdvalid=train_dataset[size+size:]\n",
        "        firsttrain=secondvalid+thirdvalid\n",
        "        secondtrain=firstvalid+thirdvalid\n",
        "        thirdtrain=firstvalid+secondvalid\n",
        "        return firsttrain,firstvalid,secondtrain,secondvalid,thirdtrain,thirdvalid,train_dataset,pos_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L6MMAFUL4_To",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# chipseq=Chip('/content/drive/My Drive/Deepbind/ZBTB7A_HepG2_ZBTB7A_(SC-34508)_HudsonAlpha_AC.seq.gz')\n",
        "chipseq=Chip('/content/drive/My Drive/Colab Notebooks/Chip-seq/ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz')\n",
        "# chipseq=Chip('/content/drive/My Drive/Colab Notebooks/Chip-seq/USF1_HepG2_USF-1_HudsonAlpha_AC.seq.gz')\n",
        "\n",
        "\n",
        "train1,valid1,train2,valid2,train3,valid3,alldataset,pos_data=chipseq.openFile()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NpL5astj79qG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Embedding Vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "CTmQKh-s782v",
        "colab_type": "code",
        "outputId": "ee2e425a-7389-482d-a965-98a19c68e71a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim\n",
        "# imports needed and set up logging\n",
        "import gzip\n",
        "import gensim \n",
        "# import logging\n",
        "import multiprocessing\n",
        "\n",
        "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.67)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.67 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.67)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.67->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uOcnhRPSBtZ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Gen_Words(pos_data,kmer_len,s):\n",
        "    out=[]\n",
        "\n",
        "    for i in pos_data:\n",
        "\n",
        "        kmer_list=[]\n",
        "        for j in range(0,(len(i)-kmer_len)+1,s):\n",
        "\n",
        "              kmer_list.append(i[j:j+kmer_len])\n",
        "\n",
        "        out.append(kmer_list)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZdtlDGpkfrq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "document= Gen_Words(pos_data,5,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ys2kiMcv785e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "Embepochs=100\n",
        "Embsize=50\n",
        "model = gensim.models.Word2Vec (document, size=Embsize,workers=multiprocessing.cpu_count())\n",
        "model.train(document,total_examples=len(document),epochs=Embepochs)\n",
        "# print(model.wv.vectors)\n",
        "model.save(\"/content/drive/My Drive/Colab Notebooks/Model\"+str(Embepochs)+\"epochs\"+str(Embsize)+\"EmbSize\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bd7fVO4Vr3JF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's Create our GRU Model!"
      ]
    },
    {
      "metadata": {
        "id": "PcVAE_cH4_Wb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class chipseq_dataset(Dataset):\n",
        "    \"\"\" Diabetes dataset.\"\"\"\n",
        "\n",
        "    def __init__(self,xy=None,model=None,kmer_len=5,stride=2):\n",
        "      \n",
        "        self.kmer_len= kmer_len\n",
        "        self.stride= stride\n",
        "        data=[el[0] for el in xy]\n",
        "        words_doc= self.Gen_Words(data,self.kmer_len,self.stride)\n",
        "#         print(words_doc[0])\n",
        "        x_data=[self.convert_data_to_index(el,model.wv) for el in words_doc]\n",
        "#         print(x_data[0])\n",
        "       \n",
        "        \n",
        "        self.x_data=np.asarray(x_data,dtype=np.float32)\n",
        "        self.y_data =np.asarray([el[1] for el in xy ],dtype=np.float32)\n",
        "        self.x_data = torch.LongTensor(self.x_data)\n",
        "        self.y_data = torch.from_numpy(self.y_data)\n",
        "        self.len=len(self.x_data)\n",
        "      \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "      \n",
        "    def Gen_Words(self,pos_data,kmer_len,s):\n",
        "        out=[]\n",
        "        \n",
        "        for i in pos_data:\n",
        "\n",
        "            kmer_list=[]\n",
        "            for j in range(0,(len(i)-kmer_len)+1,s):\n",
        "\n",
        "                  kmer_list.append(i[j:j+kmer_len])\n",
        "                \n",
        "            out.append(kmer_list)\n",
        "            \n",
        "        return out\n",
        "\n",
        "\n",
        "    def convert_data_to_index(self, string_data, wv):\n",
        "      index_data = []\n",
        "      for word in string_data:\n",
        "          if word in wv:\n",
        "              index_data.append(wv.vocab[word].index)\n",
        "      return index_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iLZSwcwU4_Z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kmer_len=5\n",
        "stride=2\n",
        "\n",
        "Embepochs=100\n",
        "Embsize=50\n",
        "\n",
        "model1 = gensim.models.Word2Vec.load(\"/content/drive/My Drive/Colab Notebooks/Model\"+str(Embepochs)+\"epochs\"+str(Embsize)+\"EmbSize\")\n",
        "train1_dataset=chipseq_dataset(train1,model1,kmer_len,stride)\n",
        "train2_dataset=chipseq_dataset(train2,model1,kmer_len,stride)\n",
        "train3_dataset=chipseq_dataset(train3,model1,kmer_len,stride)\n",
        "valid1_dataset=chipseq_dataset(valid1,model1,kmer_len,stride)\n",
        "valid2_dataset=chipseq_dataset(valid2,model1,kmer_len,stride)\n",
        "valid3_dataset=chipseq_dataset(valid3,model1,kmer_len,stride)\n",
        "alldataset_dataset=chipseq_dataset(alldataset,model1,kmer_len,stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXSLw-oyDNH6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchSize=200\n",
        "\n",
        "train_loader1 = DataLoader(dataset=train1_dataset,batch_size=batchSize,shuffle=True)\n",
        "train_loader2 = DataLoader(dataset=train2_dataset,batch_size=batchSize,shuffle=True)\n",
        "train_loader3 = DataLoader(dataset=train3_dataset,batch_size=batchSize,shuffle=True)\n",
        "valid1_loader = DataLoader(dataset=valid1_dataset,batch_size=batchSize,shuffle=False)\n",
        "valid2_loader = DataLoader(dataset=valid2_dataset,batch_size=batchSize,shuffle=False)\n",
        "valid3_loader = DataLoader(dataset=valid3_dataset,batch_size=batchSize,shuffle=False)\n",
        "alldataset_loader=DataLoader(dataset=alldataset_dataset,batch_size=batchSize,shuffle=True)\n",
        "\n",
        "train_dataloader=[train_loader1,train_loader2,train_loader3]\n",
        "valid_dataloader=[valid1_loader,valid2_loader,valid3_loader]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgKigIehq0bl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# input of shape(batch_size,inp_chan,iW)\n",
        "class GRUNet(nn.Module):\n",
        "    def __init__(self, hidden_size,dropprob,stdneu):\n",
        "      \n",
        "        super(GRUNet, self).__init__()\n",
        "        \n",
        "        model1 = gensim.models.Word2Vec.load(\"/content/drive/My Drive/Colab Notebooks/Model\"+str(Embepochs)+\"epochs\"+str(Embsize)+\"EmbSize\")\n",
        "        weights = torch.FloatTensor(model1.wv.vectors)\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights, freeze=False)\n",
        "        # Get embeddings for index 1\n",
        "#         input = torch.LongTensor([1,2])\n",
        "#         print(input)\n",
        "        \n",
        "        \n",
        "        self.hidden_size=hidden_size\n",
        "        self.rnn = nn.GRU(Embsize, hidden_size, num_layers=1, bidirectional=True).to(device)\n",
        "        self.wHidden = torch.normal(torch.zeros(2*hidden_size,1)).to(device)\n",
        "        self.wHiddenBias = torch.randn(1).to(device)\n",
        "        torch.nn.init.xavier_uniform(self.wHidden)\n",
        "        self.wHidden.requires_grad=True\n",
        "        self.wHiddenBias.requires_grad=True\n",
        "        self.drop1=nn.Dropout(p=dropprob).to(device)\n",
        "        self.FC2= nn.Linear(20,1,bias=True).to(device)\n",
        "        \n",
        "   \n",
        "        for layer_p in self.rnn._all_weights:\n",
        "            for p in layer_p:\n",
        "                if 'weight' in p:\n",
        "                    # print(p, self.rnn.__getattr__(p))\n",
        "                    nn.init.xavier_uniform(self.rnn.__getattr__(p))\n",
        "       \n",
        "    def forward(self, x):\n",
        "    \n",
        "    \n",
        "    \n",
        "#       input = torch.LongTensor(x)\n",
        "      \n",
        "      x_emb= self.embedding(x)\n",
        "#       print(x_emb[1,1,:])\n",
        "      x_emb=x_emb.permute(1,0,2)\n",
        "      output, hn = self.rnn(x_emb)\n",
        "      ## from (1, N, hidden) to (N, hidden)\n",
        "#       rearranged = hn.view(hn.size()[1], hn.size(2))\n",
        "      Normal_GRU=output[-1, :, :self.hidden_size]\n",
        "      Rev_GRU=output[0, :, self.hidden_size:]\n",
        "      Concat_GRU = torch.cat((Normal_GRU, Rev_GRU), 1)\n",
        "      Concat_GRU=self.drop1(Concat_GRU)\n",
        "      hid=Concat_GRU @ self.wHidden\n",
        "      hid.add_(self.wHiddenBias)\n",
        "#       inter=F.relu(hid)\n",
        "#       inter=self.drop1(inter)\n",
        "#       hid=self.FC2(inter)\n",
        "      output = torch.sigmoid(hid)\n",
        "      return output\n",
        "      \n",
        "      \n",
        "     \n",
        "        \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E7w59YRSrAnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  \n",
        "# print(device)\n",
        "learning_rate=0.01\n",
        "momentum_rate=0.95\n",
        "hidden_size=80\n",
        "Embepochs=100\n",
        "Embsize=50\n",
        "dropprob=0.6\n",
        "stdneu=1e-2\n",
        "\n",
        "for CV in range(3):\n",
        "  model = GRUNet(hidden_size,dropprob,stdneu).to(device)\n",
        "#   optimizer = torch.optim.SGD([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate, momentum=momentum_rate,weight_decay=1e-5)\n",
        "#   optimizer = torch.optim.Adam([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr = learning_rate, weight_decay=1e-5)\n",
        "  optimizer= torch.optim.Adagrad([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate, weight_decay=1e-2)\n",
        "\n",
        "  model.train()\n",
        "  for iter in range(50):\n",
        "    for i ,(data,target) in enumerate(train_dataloader[CV]):\n",
        "#         print(data.shape)\n",
        "#         data= data.permute(2,0,1)\n",
        "        data = data.to(device)\n",
        "        \n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        loss = F.binary_cross_entropy(output,target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    ## Train Auc\n",
        "    auc=[]\n",
        "    for i, (data, target) in enumerate(train_dataloader[CV]):\n",
        "#         data= data.permute(2,0,1)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "    print('AUC performance for training', np.mean(auc))\n",
        "    \n",
        "    \n",
        "    auc=[]\n",
        "    for i, (data, target) in enumerate(valid_dataloader[CV]):\n",
        "#         data= data.permute(2,0,1)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "    print('AUC performance ', np.mean(auc))\n",
        "    \n",
        "  print('        Fold Done!           ##########################################               ')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ortms66UA5Ed",
        "colab_type": "code",
        "outputId": "e4afc921-c644-4fb0-c534-b0c5bfae26a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19582
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  \n",
        "# print(device)\n",
        "learning_rate=0.05\n",
        "momentum_rate=0.95\n",
        "hidden_size=80 #=50\n",
        "Embepochs=100\n",
        "Embsize=50\n",
        "dropprob=0.6# =0.6\n",
        "\n",
        "best_auc=0\n",
        "for stdneu in [1e-3, 1e-4, 1e-5]:\n",
        "  for hidden_size in [50,80,100]:\n",
        "    for learning_rate in [0.05, 0.02,0.01, 0.001]:\n",
        "      for weight_decay in [1e-2, 1e-3, 1e-10]:\n",
        "          AUC_all=[]\n",
        "          \n",
        "          for CV in range(3):\n",
        "            model = GRUNet(hidden_size,dropprob,stdneu).to(device)\n",
        "          #   optimizer = torch.optim.SGD([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate, momentum=momentum_rate,weight_decay=1e-2)\n",
        "          #   optimizer = torch.optim.Adam([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr = learning_rate, weight_decay=1e-2)\n",
        "            optimizer= torch.optim.Adagrad([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "            model.train()\n",
        "            for iter in range(50):\n",
        "              for i ,(data,target) in enumerate(train_dataloader[CV]):\n",
        "          #         print(data.shape)\n",
        "          #         data= data.permute(2,0,1)\n",
        "                  data = data.to(device)\n",
        "\n",
        "                  target = target.to(device)\n",
        "                  output = model(data)\n",
        "                  loss = F.binary_cross_entropy(output,target)\n",
        "                  optimizer.zero_grad()\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              ## Train Auc\n",
        "              auc=[]\n",
        "              for i, (data, target) in enumerate(train_dataloader[CV]):\n",
        "          #         data= data.permute(2,0,1)\n",
        "                  data = data.to(device)\n",
        "                  target = target.to(device)\n",
        "\n",
        "                  # Forward pass\n",
        "                  output = model(data)\n",
        "                  pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                  labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "                  auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "              print('AUC performance for training', np.mean(auc))\n",
        "\n",
        "\n",
        "              auc=[]\n",
        "              for i, (data, target) in enumerate(valid_dataloader[CV]):\n",
        "          #         data= data.permute(2,0,1)\n",
        "                  data = data.to(device)\n",
        "                  target = target.to(device)\n",
        "\n",
        "                  # Forward pass\n",
        "                  output = model(data)\n",
        "                  pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                  labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "                  auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "              print('AUC performance ', np.mean(auc))\n",
        "              AUC_all.append(np.mean(auc))\n",
        "            print('   #####     Fold Done!           ##########################################               ')\n",
        "          print( '====================================  ONE CROSS VALIDATION DONE !! ===========================================')\n",
        "          if best_auc < np.mean(AUC_all):\n",
        "            best_auc=np.mean(AUC_all)\n",
        "            best_hidden_size=hidden_size\n",
        "            best_learning_rate=learning_rate\n",
        "            best_weight_decay=weight_decay\n",
        "            print('================================= Best Parametyers So Far!!! ========================================', best_auc,best_hidden_size,best_learning_rate,best_weight_decay)            \n",
        "\n",
        "print('Finally!!!! best AUC:   ', best_auc, '   best parameters:   ', best_hidden_size,best_learning_rate,best_weight_decay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC performance for training 0.896127696977188\n",
            "AUC performance  0.854650505050505\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9209047125924446\n",
            "AUC performance  0.8259654188948308\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9303222532668196\n",
            "AUC performance  0.7870200435729846\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "================================= Best Parametyers So Far!!! ======================================== 0.8225453225061067 50 0.05 0.01\n",
            "AUC performance for training 0.9948282620315934\n",
            "AUC performance  0.8219837195484254\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9995064964413002\n",
            "AUC performance  0.8181897207367796\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9993526479893134\n",
            "AUC performance  0.7883622367465504\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.999544909679549\n",
            "AUC performance  0.8058019013666071\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999402540898534\n",
            "AUC performance  0.7944035056446821\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9993271068727422\n",
            "AUC performance  0.7798823529411765\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9266065515827849\n",
            "AUC performance  0.863129055258467\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9616861252756828\n",
            "AUC performance  0.8308671420083185\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9559479092116661\n",
            "AUC performance  0.7978663761801017\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "================================= Best Parametyers So Far!!! ======================================== 0.830620857815629 50 0.02 0.01\n",
            "AUC performance for training 0.998249397766048\n",
            "AUC performance  0.860205109922757\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.999336392277319\n",
            "AUC performance  0.8273549613784908\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9988890958675583\n",
            "AUC performance  0.8042942628903413\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9997497022787778\n",
            "AUC performance  0.8568545454545455\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9994089377150187\n",
            "AUC performance  0.8251036244800951\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9920632780234444\n",
            "AUC performance  0.7904072621641248\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9433470448869452\n",
            "AUC performance  0.8825876411170528\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9507541560589843\n",
            "AUC performance  0.8407042186571598\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9579837197583456\n",
            "AUC performance  0.8065461147421932\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "================================= Best Parametyers So Far!!! ======================================== 0.843279324838802 50 0.01 0.01\n",
            "AUC performance for training 0.9885404195068519\n",
            "AUC performance  0.8687725490196078\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9939808039919836\n",
            "AUC performance  0.8349881164587046\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.992832933697913\n",
            "AUC performance  0.7996097312999274\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9955291708284271\n",
            "AUC performance  0.8578496732026144\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9973808308787815\n",
            "AUC performance  0.8212169934640523\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9954913077771221\n",
            "AUC performance  0.7918061728395063\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.6642767382117974\n",
            "AUC performance  0.609235531788473\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.7012038758023107\n",
            "AUC performance  0.6272647653000594\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6545118734998812\n",
            "AUC performance  0.6176992011619463\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8612760089226469\n",
            "AUC performance  0.8276988710635769\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8824535422456526\n",
            "AUC performance  0.8158884135472372\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8953132761091361\n",
            "AUC performance  0.7921847494553377\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8698272590367346\n",
            "AUC performance  0.8371966726084373\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8855849772128777\n",
            "AUC performance  0.8089796791443851\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9022541723161236\n",
            "AUC performance  0.8040352941176471\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8916813383953229\n",
            "AUC performance  0.8618409982174688\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9364646408060545\n",
            "AUC performance  0.8342395721925133\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9372924789546294\n",
            "AUC performance  0.8125610748002904\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9996751245817821\n",
            "AUC performance  0.8331982768865122\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999941082202113\n",
            "AUC performance  0.8202251336898395\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9995887448836481\n",
            "AUC performance  0.7842868554829339\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8209503267973857\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8019397504456328\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9911098877489151\n",
            "AUC performance  0.7570999273783587\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9414907051472551\n",
            "AUC performance  0.87454165181224\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.960819503455294\n",
            "AUC performance  0.8402046345811052\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.957895095654397\n",
            "AUC performance  0.807129702251271\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9976002002872651\n",
            "AUC performance  0.831996137849079\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9998540962478418\n",
            "AUC performance  0.8233329174093881\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997802615407193\n",
            "AUC performance  0.8047266521423383\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999881595150137\n",
            "AUC performance  0.8524948306595366\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999763092468598\n",
            "AUC performance  0.8292248366013072\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7936927378358751\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9576356812237747\n",
            "AUC performance  0.8861033868092691\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9595834979827284\n",
            "AUC performance  0.8340525252525253\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9601970062512976\n",
            "AUC performance  0.8125771968046478\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "================================= Best Parametyers So Far!!! ======================================== 0.8442443696221474 80 0.01 0.01\n",
            "AUC performance for training 0.9983215718243164\n",
            "AUC performance  0.8639689839572192\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9991594786959945\n",
            "AUC performance  0.8282020202020202\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9989819179041424\n",
            "AUC performance  0.800326797385621\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9994731875471574\n",
            "AUC performance  0.8671551990493167\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9994209105880469\n",
            "AUC performance  0.8304553773024361\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997974282195919\n",
            "AUC performance  0.8033633986928104\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.7728916604048158\n",
            "AUC performance  0.7181346405228757\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.7061493998071099\n",
            "AUC performance  0.6364767676767676\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6547462849756119\n",
            "AUC performance  0.6187124183006537\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8882339199320223\n",
            "AUC performance  0.8532065359477123\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9049816691891754\n",
            "AUC performance  0.8196191325014854\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9108718228793274\n",
            "AUC performance  0.7924259985475672\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8937700538284566\n",
            "AUC performance  0.8591050505050505\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9074283608564271\n",
            "AUC performance  0.8172349376114082\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9252034931827584\n",
            "AUC performance  0.8141408859840232\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9092122233383886\n",
            "AUC performance  0.8600592988710636\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9284762929460942\n",
            "AUC performance  0.8273713606654782\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9363051408145546\n",
            "AUC performance  0.8084960058097312\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9998539966197697\n",
            "AUC performance  0.8245393345216874\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9998686803769538\n",
            "AUC performance  0.8159449197860963\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999880000959991\n",
            "AUC performance  0.7763295570079883\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8248723707664884\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8195764111705288\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999466463447017\n",
            "AUC performance  0.7907504720406682\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9494702442915101\n",
            "AUC performance  0.8714423054070113\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9647963877106976\n",
            "AUC performance  0.8366343434343435\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9625411932933445\n",
            "AUC performance  0.8030271604938272\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9998410369528322\n",
            "AUC performance  0.8525638146167557\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8206177064765301\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7983525780682643\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8647007724301842\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8316817587641117\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7941647785039943\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9418368259261669\n",
            "AUC performance  0.8852039215686274\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9577279426831194\n",
            "AUC performance  0.840675816993464\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9589282914374603\n",
            "AUC performance  0.8143731299927377\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "================================= Best Parametyers So Far!!! ======================================== 0.846750956184943 100 0.01 0.01\n",
            "AUC performance for training 0.9995889901890005\n",
            "AUC performance  0.8706067736185382\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9923825485644558\n",
            "AUC performance  0.825612358882947\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9998056059355771\n",
            "AUC performance  0.7966137981118374\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9993358113309002\n",
            "AUC performance  0.8732967320261438\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999702911467617\n",
            "AUC performance  0.8354437908496732\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9998813985481289\n",
            "AUC performance  0.8027707334785766\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.7266414299074222\n",
            "AUC performance  0.6602055852644089\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.7098171849405438\n",
            "AUC performance  0.634800118835413\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6741942542636711\n",
            "AUC performance  0.6329718228031953\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8975479943095144\n",
            "AUC performance  0.8774363636363637\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9135090426948737\n",
            "AUC performance  0.824691265597148\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9208768310998025\n",
            "AUC performance  0.7947610748002906\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9118198780625002\n",
            "AUC performance  0.8824259061200238\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9180558967389483\n",
            "AUC performance  0.8294743909685086\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9275491044975179\n",
            "AUC performance  0.806432970225127\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9011029761245519\n",
            "AUC performance  0.8596569221628044\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9363503693935564\n",
            "AUC performance  0.8390218657159834\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9288787762461892\n",
            "AUC performance  0.7912421205519244\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9990631359362654\n",
            "AUC performance  0.8314457516339869\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9989564091809614\n",
            "AUC performance  0.8103840760546644\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9985939549441407\n",
            "AUC performance  0.7890851851851852\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.999887698866476\n",
            "AUC performance  0.8104836601307189\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9993052809359874\n",
            "AUC performance  0.7950721330956625\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9991608953196058\n",
            "AUC performance  0.7576573710965869\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9412475131584264\n",
            "AUC performance  0.8699358288770053\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9611531659872895\n",
            "AUC performance  0.8369133689839572\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9513802155818089\n",
            "AUC performance  0.7908989106753812\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9881401076526575\n",
            "AUC performance  0.8393776589423648\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9991725721112007\n",
            "AUC performance  0.8266820558526442\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9982176673615183\n",
            "AUC performance  0.796358896151053\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999587385174865\n",
            "AUC performance  0.8681622697563874\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9998165049061669\n",
            "AUC performance  0.8277631610219846\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997382840120572\n",
            "AUC performance  0.7921650689905592\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.940078939764788\n",
            "AUC performance  0.8749828877005348\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9667962443819474\n",
            "AUC performance  0.8462969696969695\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9540536793469692\n",
            "AUC performance  0.8076309368191722\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9871711495677383\n",
            "AUC performance  0.8648879382055852\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.994368783783513\n",
            "AUC performance  0.8308412358882946\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9928060927315383\n",
            "AUC performance  0.7982413217138709\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.995685343283164\n",
            "AUC performance  0.8625163398692812\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.996613951619356\n",
            "AUC performance  0.823982055852644\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9954695154393026\n",
            "AUC performance  0.7952560639070443\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.6602831462472448\n",
            "AUC performance  0.605179916815211\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8282973173611933\n",
            "AUC performance  0.7895105169340464\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6483927531233252\n",
            "AUC performance  0.6112840958605663\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8396327021580858\n",
            "AUC performance  0.819159120617944\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8774738593760821\n",
            "AUC performance  0.8082281639928698\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9019975001089513\n",
            "AUC performance  0.7961789397240377\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8546367608180475\n",
            "AUC performance  0.8231636363636362\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.88762006987894\n",
            "AUC performance  0.8223449792038027\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8936941637625693\n",
            "AUC performance  0.7984676833696441\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8902175157741242\n",
            "AUC performance  0.8661803921568627\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9339405452411897\n",
            "AUC performance  0.8329582887700535\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9251438494684234\n",
            "AUC performance  0.7914011619462601\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9998756063362848\n",
            "AUC performance  0.8441960784313726\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997872855946348\n",
            "AUC performance  0.8084699346405229\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999463883911822\n",
            "AUC performance  0.7847336238198983\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8106072489601901\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8049559120617943\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.999994115293176\n",
            "AUC performance  0.7803358750907771\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9463654520071453\n",
            "AUC performance  0.8757226381461675\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9604763429215957\n",
            "AUC performance  0.8320362448009506\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9577079925691125\n",
            "AUC performance  0.809360639070443\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999344383701941\n",
            "AUC performance  0.8619525846702317\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.999650214854887\n",
            "AUC performance  0.8223038027332146\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9994204371828473\n",
            "AUC performance  0.8050669571532316\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999747000044361\n",
            "AUC performance  0.8555259061200238\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999881927881551\n",
            "AUC performance  0.830684670231729\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7996055918663763\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9446735830126748\n",
            "AUC performance  0.8821208556149732\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9531055600465095\n",
            "AUC performance  0.8305768270944742\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9609555546445548\n",
            "AUC performance  0.804830646332607\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9988669847423308\n",
            "AUC performance  0.8667817587641116\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.999119514816375\n",
            "AUC performance  0.8287740938799761\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9978558673510809\n",
            "AUC performance  0.8099596223674655\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.99939050903124\n",
            "AUC performance  0.8645407011289364\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9994436506789613\n",
            "AUC performance  0.8277567439096851\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997402140670033\n",
            "AUC performance  0.8001123456790122\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.7014679382693629\n",
            "AUC performance  0.6363889483065952\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6756659699988316\n",
            "AUC performance  0.6101226381461675\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6779356581428698\n",
            "AUC performance  0.6358933914306463\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8713821957117505\n",
            "AUC performance  0.8491262032085561\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.900200306600429\n",
            "AUC performance  0.8073038621509209\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9069284550417321\n",
            "AUC performance  0.7941416122004357\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.882775227133125\n",
            "AUC performance  0.8655420083184788\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9109885510287978\n",
            "AUC performance  0.82537183600713\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9228196002626745\n",
            "AUC performance  0.8042081336238198\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9020601647974177\n",
            "AUC performance  0.8681404634581106\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9310403268298351\n",
            "AUC performance  0.8354578728461081\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9403810416688398\n",
            "AUC performance  0.8176444444444444\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9992897189207338\n",
            "AUC performance  0.8337638740344623\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999940963940775\n",
            "AUC performance  0.816913844325609\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999757003282798\n",
            "AUC performance  0.7834977487291213\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8120866310160428\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8004226975638741\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7878604938271604\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9431551607805476\n",
            "AUC performance  0.8738816399286988\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9622387071756322\n",
            "AUC performance  0.8404166369578133\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9590584665410967\n",
            "AUC performance  0.8006098765432098\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999881927881551\n",
            "AUC performance  0.8459794414735591\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999289570900823\n",
            "AUC performance  0.8287549019607843\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9998756553164322\n",
            "AUC performance  0.8014451706608569\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.84319376114082\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8277136066547831\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7918074074074074\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9556806902949195\n",
            "AUC performance  0.886827807486631\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9696894887830154\n",
            "AUC performance  0.8460998217468806\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9575065153761292\n",
            "AUC performance  0.8078861292665215\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "================================= Best Parametyers So Far!!! ======================================== 0.846937919500011 100 0.01 0.01\n",
            "AUC performance for training 0.9988989850628139\n",
            "AUC performance  0.860940166369578\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9996864342971227\n",
            "AUC performance  0.8243095662507427\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9993379722519103\n",
            "AUC performance  0.8045086419753087\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999645164345933\n",
            "AUC performance  0.8703904337492574\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999698155124119\n",
            "AUC performance  0.8433489007724302\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997212508088086\n",
            "AUC performance  0.8028666666666666\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.7402313794039568\n",
            "AUC performance  0.679761853832442\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6998821871065626\n",
            "AUC performance  0.6286115270350564\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6919448761897238\n",
            "AUC performance  0.6464386347131444\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8884408524260218\n",
            "AUC performance  0.8700375519904932\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9134031021506636\n",
            "AUC performance  0.8254108140225787\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9233165632062001\n",
            "AUC performance  0.8155074800290487\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8964170851849159\n",
            "AUC performance  0.845759595959596\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.930458742769165\n",
            "AUC performance  0.8357535353535354\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9082922466651826\n",
            "AUC performance  0.7780273057371097\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8882713278756491\n",
            "AUC performance  0.8613532976827094\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9344686632510516\n",
            "AUC performance  0.8317269162210339\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9310640663770909\n",
            "AUC performance  0.783350181554103\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9991663188777304\n",
            "AUC performance  0.8443833630421865\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9990250574533406\n",
            "AUC performance  0.8000770647652999\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.999691874916756\n",
            "AUC performance  0.7797753812636165\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999703958328929\n",
            "AUC performance  0.8000269756387404\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9990767695452428\n",
            "AUC performance  0.8017490196078431\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9962743303745952\n",
            "AUC performance  0.7766106027596225\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.937746829666013\n",
            "AUC performance  0.8712997029114675\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9565648257220242\n",
            "AUC performance  0.8274143790849673\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.955974541558137\n",
            "AUC performance  0.7941134350036311\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9989621625589699\n",
            "AUC performance  0.863992038027332\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9980734658102343\n",
            "AUC performance  0.8255638740344623\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.998059750782883\n",
            "AUC performance  0.8021748002904864\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.999686635634779\n",
            "AUC performance  0.8562433749257279\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9989550348458609\n",
            "AUC performance  0.8181273915626858\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9986945395814848\n",
            "AUC performance  0.7890874364560638\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9399609156766338\n",
            "AUC performance  0.8769278669043375\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9638488186573362\n",
            "AUC performance  0.8402066547831254\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.954073666488855\n",
            "AUC performance  0.8050069716775599\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9935963513300999\n",
            "AUC performance  0.8667206179441473\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9900097198403247\n",
            "AUC performance  0.8373334521687462\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9915903879608827\n",
            "AUC performance  0.8062156862745098\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9949841603021872\n",
            "AUC performance  0.8598362448009507\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.997417511317264\n",
            "AUC performance  0.8294123588829471\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9915314197296756\n",
            "AUC performance  0.7849500363108205\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.7261079296168129\n",
            "AUC performance  0.6625937017231135\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.7213226203912084\n",
            "AUC performance  0.6580792632204397\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.863257878685386\n",
            "AUC performance  0.7929042846768337\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.845932862324982\n",
            "AUC performance  0.8210497920380274\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8718896376887024\n",
            "AUC performance  0.8052080808080809\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8917587432298124\n",
            "AUC performance  0.7980535947712419\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8509108274506758\n",
            "AUC performance  0.814017825311943\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8805031808708763\n",
            "AUC performance  0.8193856209150326\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8933823769797182\n",
            "AUC performance  0.794327087872186\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8983845250916004\n",
            "AUC performance  0.8640527629233512\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9341294059889892\n",
            "AUC performance  0.8292112893642305\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9355207408463185\n",
            "AUC performance  0.8099047204066812\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999409251241408\n",
            "AUC performance  0.8316862150920974\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997379547247484\n",
            "AUC performance  0.8105597147950089\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9982131260438948\n",
            "AUC performance  0.7854961510530138\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999646917590566\n",
            "AUC performance  0.813012715389186\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9996795182431003\n",
            "AUC performance  0.7978229946524065\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.779639070442992\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9431474336781395\n",
            "AUC performance  0.8780508615567438\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9562273934914042\n",
            "AUC performance  0.8302623885918003\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9597913570215276\n",
            "AUC performance  0.8041298474945533\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9999586624632096\n",
            "AUC performance  0.8613503267973855\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999291359792466\n",
            "AUC performance  0.8301292929292929\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999882305863522\n",
            "AUC performance  0.789264705882353\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8534131907308379\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8292172311348781\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999760008690004\n",
            "AUC performance  0.7952044299201162\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9570258228868639\n",
            "AUC performance  0.8835845513963162\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9592022191886097\n",
            "AUC performance  0.8339322638146167\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9601338370844216\n",
            "AUC performance  0.8149404502541757\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9970642146983166\n",
            "AUC performance  0.865132917409388\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9988369539334284\n",
            "AUC performance  0.8313812240047533\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9987688886980074\n",
            "AUC performance  0.7993251997095134\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9997416802963902\n",
            "AUC performance  0.863120202020202\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997465063481383\n",
            "AUC performance  0.8331145573380867\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9995017485958736\n",
            "AUC performance  0.8016964415395786\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.6813554206553425\n",
            "AUC performance  0.6238843731431968\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8800873466903703\n",
            "AUC performance  0.8129675579322637\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6670993770263023\n",
            "AUC performance  0.6262236746550471\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8732677071756838\n",
            "AUC performance  0.8518033273915626\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9127971323716815\n",
            "AUC performance  0.8361657754010695\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9064728671822607\n",
            "AUC performance  0.7897655773420479\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8846521616312982\n",
            "AUC performance  0.8380446821152703\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9135536724045877\n",
            "AUC performance  0.8286746286393346\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9187035313836989\n",
            "AUC performance  0.8065859114015976\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.898583894133886\n",
            "AUC performance  0.8614698752228164\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9306412679502791\n",
            "AUC performance  0.8316165181224004\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9269927429200716\n",
            "AUC performance  0.7876748002904865\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8515780154486038\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999704172022218\n",
            "AUC performance  0.8083723113487817\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999821912186043\n",
            "AUC performance  0.784439070442992\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.828997385620915\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8142673796791443\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999881379868593\n",
            "AUC performance  0.7840799564270152\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9488939291378713\n",
            "AUC performance  0.8781431966726084\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9659781355895085\n",
            "AUC performance  0.8344967320261437\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9563997845819708\n",
            "AUC performance  0.8029816993464053\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8634016042780749\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.99998803175159\n",
            "AUC performance  0.8238320855614973\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.787754829339143\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8616651218062982\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.8344156268568034\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 1.0\n",
            "AUC performance  0.7823045025417573\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9518061710407665\n",
            "AUC performance  0.8849319073083779\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9562070715403412\n",
            "AUC performance  0.8446342245989303\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9595714611268623\n",
            "AUC performance  0.8056472040668119\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.999237583230682\n",
            "AUC performance  0.8695385026737968\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9997603846179721\n",
            "AUC performance  0.8277273321449791\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9991827252792388\n",
            "AUC performance  0.7991379811183732\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.9996501128549369\n",
            "AUC performance  0.8657545454545454\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999940963940775\n",
            "AUC performance  0.827114973262032\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9999881664495635\n",
            "AUC performance  0.7911529411764706\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8333128043236436\n",
            "AUC performance  0.8291639928698753\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.8156463677869188\n",
            "AUC performance  0.7748162804515746\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.6941189681047718\n",
            "AUC performance  0.6484976034858387\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8822161395157546\n",
            "AUC performance  0.8612171122994653\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9173346630800846\n",
            "AUC performance  0.8337051693404636\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9235113440297388\n",
            "AUC performance  0.810050108932462\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "AUC performance for training 0.8980910937193003\n",
            "AUC performance  0.8604991087344028\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9305609180954479\n",
            "AUC performance  0.8270831847890672\n",
            "   #####     Fold Done!           ##########################################               \n",
            "AUC performance for training 0.9298622636693418\n",
            "AUC performance  0.8109353667392883\n",
            "   #####     Fold Done!           ##########################################               \n",
            "====================================  ONE CROSS VALIDATION DONE !! ===========================================\n",
            "Finally!!!! best AUC:    0.846937919500011    best parameters:    100 0.01 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M6vE2wLiA5G9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5YkPC0-4A5Jz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hhbfpTvlRs_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing Phase! (Training on all Training data)"
      ]
    },
    {
      "metadata": {
        "id": "B2hSleu8OkF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Chip_test():\n",
        "    def __init__(self,filename):\n",
        "        self.file = filename\n",
        "            \n",
        "    def openFile(self):\n",
        "        data_all=[]\n",
        "        pos_data=[]\n",
        "\n",
        "        with gzip.open(self.file, 'rt') as data:\n",
        "            next(data)\n",
        "            reader = csv.reader(data,delimiter='\\t')\n",
        "\n",
        "            for row in reader:\n",
        "\n",
        "                ## When using Embedding\n",
        "                data_all.append([row[2],[int(row[3])]])\n",
        "\n",
        "\n",
        "#         random.shuffle(train_dataset)\n",
        "        train_dataset=data_all\n",
        "\n",
        "\n",
        "        return train_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jvONy3vjA5Md",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chipseq_test=Chip_test('/content/drive/My Drive/Colab Notebooks/Chip-seq/ELK1_GM12878_ELK1_(1277-1)_Stanford_B.seq.gz')\n",
        "# chipseq_test=Chip_test('/content/drive/My Drive/Colab Notebooks/Chip-seq/USF1_HepG2_USF-1_HudsonAlpha_B.seq.gz')\n",
        "test_data=chipseq_test.openFile()\n",
        "test_dataset=chipseq_dataset(test_data,model1,kmer_len,stride)\n",
        "batchSize=test_dataset.__len__()\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=batchSize,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uWKa5eusOWg9",
        "colab_type": "code",
        "outputId": "17ebad1b-d34f-4aca-ba03-9a4dc22af757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  \n",
        "# print(device)\n",
        "learning_rate=0.02\n",
        "momentum_rate=0.95\n",
        "hidden_size=80\n",
        "Embepochs=100\n",
        "Embsize=50\n",
        "dropprob=0.8\n",
        "stdneu=1e-5\n",
        "lr_dec= learning_rate / 200\n",
        "\n",
        "model = GRUNet(hidden_size,dropprob,stdneu).to(device)\n",
        "optimizer = torch.optim.SGD([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate, momentum=momentum_rate,weight_decay=1e-2)\n",
        "# optimizer = torch.optim.Adam([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr = learning_rate, weight_decay=1e-5)\n",
        "# optimizer= torch.optim.Adagrad([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate,lr_decay=lr_dec, weight_decay=1e-2)\n",
        "\n",
        "\n",
        "for iter in range(200):\n",
        "  model.train()\n",
        "  for i ,(data,target) in enumerate(alldataset_loader):\n",
        "#         print(data.shape)\n",
        "#         data= data.permute(2,0,1)\n",
        "      data = data.to(device)\n",
        "\n",
        "      target = target.to(device)\n",
        "      output = model(data)\n",
        "      loss = F.binary_cross_entropy(output,target)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    ## Train Auc\n",
        "    auc=[]\n",
        "    for i, (data, target) in enumerate(alldataset_loader):\n",
        "  #         data= data.permute(2,0,1)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "    print('AUC performance for training', np.mean(auc))\n",
        "     \n",
        "\n",
        "  \n",
        "\n",
        "print('       Done!           ##########################################               ')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC performance for training 0.5398152180407366\n",
            "AUC performance for training 0.5863425384973051\n",
            "AUC performance for training 0.6238028635988235\n",
            "AUC performance for training 0.6563810314145438\n",
            "AUC performance for training 0.6517396933793037\n",
            "AUC performance for training 0.6444054686747706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-fac760cd5f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-96b801e944a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#       print(x_emb[1,1,:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mx_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m       \u001b[0;31m## from (1, N, hidden) to (N, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#       rearranged = hn.view(hn.size()[1], hn.size(2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvariable_length\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             dropout_ts)\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pxb5koqppsDR",
        "colab_type": "code",
        "outputId": "3b6220a0-3834-410b-bdf8-e5aaa89e18d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13956
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  \n",
        "# print(device)\n",
        "learning_rate=0.03\n",
        "momentum_rate=0.95\n",
        "hidden_size=80\n",
        "Embepochs=100\n",
        "Embsize=50\n",
        "dropprob=0.5\n",
        "stdneu=1e-3\n",
        "lr_dec= learning_rate / 400\n",
        "\n",
        "model = GRUNet(hidden_size,dropprob,stdneu).to(device)\n",
        "# optimizer = torch.optim.SGD([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate, momentum=momentum_rate,weight_decay=1e-2)\n",
        "# optimizer = torch.optim.Adam([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr = learning_rate, weight_decay=1e-5)\n",
        "optimizer= torch.optim.Adagrad([model.wHidden,model.wHiddenBias]+[param for param in model.parameters()], lr=learning_rate,lr_decay=lr_dec, weight_decay=0.015)\n",
        "\n",
        "\n",
        "for iter in range(400):\n",
        "  model.train()\n",
        "  for i ,(data,target) in enumerate(alldataset_loader):\n",
        "#         print(data.shape)\n",
        "#         data= data.permute(2,0,1)\n",
        "      data = data.to(device)\n",
        "\n",
        "      target = target.to(device)\n",
        "      output = model(data)\n",
        "      loss = F.binary_cross_entropy(output,target)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    ## Train Auc\n",
        "    auc=[]\n",
        "    for i, (data, target) in enumerate(alldataset_loader):\n",
        "  #         data= data.permute(2,0,1)\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "        labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "        auc.append(metrics.roc_auc_score(labels, pred))\n",
        "\n",
        "    print('AUC performance for training', np.mean(auc))\n",
        "    \n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "\n",
        "          pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "          \n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #                         \n",
        "      AUC_training=np.mean(auc)\n",
        "      print('AUC on test data = ',AUC_training)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "print('       Done!           ##########################################               ')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC performance for training 0.6939058025158655\n",
            "AUC on test data =  0.5670040000000001\n",
            "AUC performance for training 0.6906519796410481\n",
            "AUC on test data =  0.562784\n",
            "AUC performance for training 0.6962773019637154\n",
            "AUC on test data =  0.583256\n",
            "AUC performance for training 0.6969872272903005\n",
            "AUC on test data =  0.563428\n",
            "AUC performance for training 0.6975014479019772\n",
            "AUC on test data =  0.5830879999999999\n",
            "AUC performance for training 0.7073679073824798\n",
            "AUC on test data =  0.578152\n",
            "AUC performance for training 0.7083424901371416\n",
            "AUC on test data =  0.58384\n",
            "AUC performance for training 0.7114190640267811\n",
            "AUC on test data =  0.588854\n",
            "AUC performance for training 0.7159469868978066\n",
            "AUC on test data =  0.585056\n",
            "AUC performance for training 0.7167401132296574\n",
            "AUC on test data =  0.588824\n",
            "AUC performance for training 0.7196249226240178\n",
            "AUC on test data =  0.58388\n",
            "AUC performance for training 0.7220145530851181\n",
            "AUC on test data =  0.592484\n",
            "AUC performance for training 0.7224499260450722\n",
            "AUC on test data =  0.5903240000000001\n",
            "AUC performance for training 0.7266800001943341\n",
            "AUC on test data =  0.594632\n",
            "AUC performance for training 0.7263253325662372\n",
            "AUC on test data =  0.587004\n",
            "AUC performance for training 0.7330808317478992\n",
            "AUC on test data =  0.6010279999999999\n",
            "AUC performance for training 0.738624782626099\n",
            "AUC on test data =  0.609\n",
            "AUC performance for training 0.7403655420960128\n",
            "AUC on test data =  0.604408\n",
            "AUC performance for training 0.7460820206594247\n",
            "AUC on test data =  0.60302\n",
            "AUC performance for training 0.7533874149872649\n",
            "AUC on test data =  0.60928\n",
            "AUC performance for training 0.8029732049895354\n",
            "AUC on test data =  0.671524\n",
            "AUC performance for training 0.7918114702969024\n",
            "AUC on test data =  0.6565559999999999\n",
            "AUC performance for training 0.776993185422261\n",
            "AUC on test data =  0.632212\n",
            "AUC performance for training 0.8088624803623208\n",
            "AUC on test data =  0.684708\n",
            "AUC performance for training 0.8355159170727907\n",
            "AUC on test data =  0.7686679999999999\n",
            "AUC performance for training 0.8469882346368589\n",
            "AUC on test data =  0.801192\n",
            "AUC performance for training 0.8502637193729701\n",
            "AUC on test data =  0.791996\n",
            "AUC performance for training 0.8527665820722001\n",
            "AUC on test data =  0.793628\n",
            "AUC performance for training 0.8600168967612584\n",
            "AUC on test data =  0.825044\n",
            "AUC performance for training 0.8706914343850416\n",
            "AUC on test data =  0.84558\n",
            "AUC performance for training 0.871882070755087\n",
            "AUC on test data =  0.8359080000000001\n",
            "AUC performance for training 0.8754675020134697\n",
            "AUC on test data =  0.8481160000000001\n",
            "AUC performance for training 0.8789741918312587\n",
            "AUC on test data =  0.8519599999999999\n",
            "AUC performance for training 0.8833934120317241\n",
            "AUC on test data =  0.8607399999999998\n",
            "AUC performance for training 0.8814891339134021\n",
            "AUC on test data =  0.8575200000000001\n",
            "AUC performance for training 0.8729495813023508\n",
            "AUC on test data =  0.8611759999999999\n",
            "AUC performance for training 0.8834239422826334\n",
            "AUC on test data =  0.8631239999999999\n",
            "AUC performance for training 0.871408263000789\n",
            "AUC on test data =  0.8551639999999999\n",
            "AUC performance for training 0.8804916658771754\n",
            "AUC on test data =  0.866036\n",
            "AUC performance for training 0.8920346207366241\n",
            "AUC on test data =  0.8763920000000001\n",
            "AUC performance for training 0.8954891146100367\n",
            "AUC on test data =  0.866624\n",
            "AUC performance for training 0.8927434911040376\n",
            "AUC on test data =  0.870752\n",
            "AUC performance for training 0.894559645466448\n",
            "AUC on test data =  0.8631800000000002\n",
            "AUC performance for training 0.8990441826670087\n",
            "AUC on test data =  0.876184\n",
            "AUC performance for training 0.8994522977449994\n",
            "AUC on test data =  0.8768159999999999\n",
            "AUC performance for training 0.9021048028027535\n",
            "AUC on test data =  0.8834040000000001\n",
            "AUC performance for training 0.8957157657873849\n",
            "AUC on test data =  0.8599239999999999\n",
            "AUC performance for training 0.9048139952284867\n",
            "AUC on test data =  0.8814719999999999\n",
            "AUC performance for training 0.9037679960954295\n",
            "AUC on test data =  0.8776919999999999\n",
            "AUC performance for training 0.8892157176941861\n",
            "AUC on test data =  0.8516919999999999\n",
            "AUC performance for training 0.8983058347409644\n",
            "AUC on test data =  0.8784359999999998\n",
            "AUC performance for training 0.906717606018249\n",
            "AUC on test data =  0.8778999999999999\n",
            "AUC performance for training 0.8999763878025381\n",
            "AUC on test data =  0.8661559999999999\n",
            "AUC performance for training 0.9104039820981654\n",
            "AUC on test data =  0.889976\n",
            "AUC performance for training 0.9103981267602148\n",
            "AUC on test data =  0.884524\n",
            "AUC performance for training 0.9033905423293274\n",
            "AUC on test data =  0.8804719999999998\n",
            "AUC performance for training 0.9077335758039679\n",
            "AUC on test data =  0.880156\n",
            "AUC performance for training 0.9089393548052843\n",
            "AUC on test data =  0.8859159999999999\n",
            "AUC performance for training 0.9088746966950112\n",
            "AUC on test data =  0.883168\n",
            "AUC performance for training 0.9068255356710566\n",
            "AUC on test data =  0.8880719999999999\n",
            "AUC performance for training 0.9105437867222534\n",
            "AUC on test data =  0.8828999999999999\n",
            "AUC performance for training 0.9067016915194906\n",
            "AUC on test data =  0.8815839999999999\n",
            "AUC performance for training 0.9132186754379057\n",
            "AUC on test data =  0.883904\n",
            "AUC performance for training 0.9121835601150103\n",
            "AUC on test data =  0.8842759999999998\n",
            "AUC performance for training 0.9099395762259225\n",
            "AUC on test data =  0.876536\n",
            "AUC performance for training 0.9100548404533242\n",
            "AUC on test data =  0.8668599999999999\n",
            "AUC performance for training 0.9106702548792374\n",
            "AUC on test data =  0.8830199999999999\n",
            "AUC performance for training 0.9155631705016859\n",
            "AUC on test data =  0.8874240000000001\n",
            "AUC performance for training 0.9076568190710997\n",
            "AUC on test data =  0.8812399999999999\n",
            "AUC performance for training 0.9027991805214758\n",
            "AUC on test data =  0.874004\n",
            "AUC performance for training 0.9140030687440751\n",
            "AUC on test data =  0.8782760000000001\n",
            "AUC performance for training 0.9158095381674936\n",
            "AUC on test data =  0.881512\n",
            "AUC performance for training 0.913088764446151\n",
            "AUC on test data =  0.8879000000000001\n",
            "AUC performance for training 0.9137458188750877\n",
            "AUC on test data =  0.8876\n",
            "AUC performance for training 0.9167082265053266\n",
            "AUC on test data =  0.8894280000000001\n",
            "AUC performance for training 0.9095253206959105\n",
            "AUC on test data =  0.879556\n",
            "AUC performance for training 0.9166800995318841\n",
            "AUC on test data =  0.885788\n",
            "AUC performance for training 0.9099371749618427\n",
            "AUC on test data =  0.8762599999999998\n",
            "AUC performance for training 0.9141458751889724\n",
            "AUC on test data =  0.8775080000000002\n",
            "AUC performance for training 0.9183390957131643\n",
            "AUC on test data =  0.8846239999999999\n",
            "AUC performance for training 0.9102009348880117\n",
            "AUC on test data =  0.8732679999999999\n",
            "AUC performance for training 0.9169818733279764\n",
            "AUC on test data =  0.8771479999999999\n",
            "AUC performance for training 0.9128093381750964\n",
            "AUC on test data =  0.879076\n",
            "AUC performance for training 0.9182841213131582\n",
            "AUC on test data =  0.8888480000000001\n",
            "AUC performance for training 0.9190473995036856\n",
            "AUC on test data =  0.888564\n",
            "AUC performance for training 0.9200977084401748\n",
            "AUC on test data =  0.889616\n",
            "AUC performance for training 0.9165652300320275\n",
            "AUC on test data =  0.892168\n",
            "AUC performance for training 0.9165431484788709\n",
            "AUC on test data =  0.891868\n",
            "AUC performance for training 0.9131133373877797\n",
            "AUC on test data =  0.8806280000000001\n",
            "AUC performance for training 0.9173488367860165\n",
            "AUC on test data =  0.8850520000000001\n",
            "AUC performance for training 0.9174406247855903\n",
            "AUC on test data =  0.8922760000000001\n",
            "AUC performance for training 0.9198872987071554\n",
            "AUC on test data =  0.884644\n",
            "AUC performance for training 0.9157478833366023\n",
            "AUC on test data =  0.8880159999999999\n",
            "AUC performance for training 0.9156328008501637\n",
            "AUC on test data =  0.884644\n",
            "AUC performance for training 0.9157169280671695\n",
            "AUC on test data =  0.872792\n",
            "AUC performance for training 0.9159465725541477\n",
            "AUC on test data =  0.8837600000000001\n",
            "AUC performance for training 0.9136639131840548\n",
            "AUC on test data =  0.8724719999999999\n",
            "AUC performance for training 0.918828802450416\n",
            "AUC on test data =  0.888764\n",
            "AUC performance for training 0.9161762776535854\n",
            "AUC on test data =  0.8802679999999999\n",
            "AUC performance for training 0.9122454575203743\n",
            "AUC on test data =  0.8804519999999999\n",
            "AUC performance for training 0.9188145077394111\n",
            "AUC on test data =  0.89086\n",
            "AUC performance for training 0.9177711530872059\n",
            "AUC on test data =  0.874856\n",
            "AUC performance for training 0.9204819860444897\n",
            "AUC on test data =  0.8929560000000001\n",
            "AUC performance for training 0.9213792553479617\n",
            "AUC on test data =  0.8865159999999999\n",
            "AUC performance for training 0.917651965080162\n",
            "AUC on test data =  0.884196\n",
            "AUC performance for training 0.9166111426098118\n",
            "AUC on test data =  0.884784\n",
            "AUC performance for training 0.9195135950793952\n",
            "AUC on test data =  0.8853439999999999\n",
            "AUC performance for training 0.9192459778666907\n",
            "AUC on test data =  0.8855519999999999\n",
            "AUC performance for training 0.9188101365179044\n",
            "AUC on test data =  0.887256\n",
            "AUC performance for training 0.9165111697121902\n",
            "AUC on test data =  0.8853\n",
            "AUC performance for training 0.9193719603061131\n",
            "AUC on test data =  0.8885000000000001\n",
            "AUC performance for training 0.9163514562681261\n",
            "AUC on test data =  0.875856\n",
            "AUC performance for training 0.9212227953751756\n",
            "AUC on test data =  0.885976\n",
            "AUC performance for training 0.9175930059490125\n",
            "AUC on test data =  0.888592\n",
            "AUC performance for training 0.9171443978664053\n",
            "AUC on test data =  0.8877280000000001\n",
            "AUC performance for training 0.9204831082645367\n",
            "AUC on test data =  0.88856\n",
            "AUC performance for training 0.917359029259127\n",
            "AUC on test data =  0.8769479999999998\n",
            "AUC performance for training 0.9211581522908032\n",
            "AUC on test data =  0.88474\n",
            "AUC performance for training 0.919690969983453\n",
            "AUC on test data =  0.878512\n",
            "AUC performance for training 0.921181492909706\n",
            "AUC on test data =  0.8854799999999998\n",
            "AUC performance for training 0.9196844960084165\n",
            "AUC on test data =  0.8874\n",
            "AUC performance for training 0.92064957199993\n",
            "AUC on test data =  0.8820520000000001\n",
            "AUC performance for training 0.9192215913197553\n",
            "AUC on test data =  0.8844399999999999\n",
            "AUC performance for training 0.91925483504638\n",
            "AUC on test data =  0.8887120000000002\n",
            "AUC performance for training 0.9170318339483373\n",
            "AUC on test data =  0.878024\n",
            "AUC performance for training 0.9195634544579424\n",
            "AUC on test data =  0.8825040000000001\n",
            "AUC performance for training 0.9218402292031544\n",
            "AUC on test data =  0.8873199999999999\n",
            "AUC performance for training 0.915977041223281\n",
            "AUC on test data =  0.8737759999999999\n",
            "AUC performance for training 0.9193532184890507\n",
            "AUC on test data =  0.8827679999999999\n",
            "AUC performance for training 0.9189226529958751\n",
            "AUC on test data =  0.8811279999999999\n",
            "AUC performance for training 0.9201093029454884\n",
            "AUC on test data =  0.8864079999999999\n",
            "AUC performance for training 0.920643348318999\n",
            "AUC on test data =  0.8820560000000001\n",
            "AUC performance for training 0.9174477913059708\n",
            "AUC on test data =  0.88462\n",
            "AUC performance for training 0.9208371569370122\n",
            "AUC on test data =  0.886644\n",
            "AUC performance for training 0.916738636619477\n",
            "AUC on test data =  0.8747959999999999\n",
            "AUC performance for training 0.9192681216070846\n",
            "AUC on test data =  0.8856759999999999\n",
            "AUC performance for training 0.9203392757698444\n",
            "AUC on test data =  0.8837359999999999\n",
            "AUC performance for training 0.9190175106492302\n",
            "AUC on test data =  0.8876360000000001\n",
            "AUC performance for training 0.9211719104993585\n",
            "AUC on test data =  0.8883319999999999\n",
            "AUC performance for training 0.9209729099899272\n",
            "AUC on test data =  0.885796\n",
            "AUC performance for training 0.9199806627867222\n",
            "AUC on test data =  0.8873559999999999\n",
            "AUC performance for training 0.9218441395817566\n",
            "AUC on test data =  0.891\n",
            "AUC performance for training 0.9204722992287667\n",
            "AUC on test data =  0.888304\n",
            "AUC performance for training 0.9060074032851392\n",
            "AUC on test data =  0.877764\n",
            "AUC performance for training 0.9207844197247599\n",
            "AUC on test data =  0.886852\n",
            "AUC performance for training 0.9172483360220841\n",
            "AUC on test data =  0.883412\n",
            "AUC performance for training 0.920289890813085\n",
            "AUC on test data =  0.8919999999999999\n",
            "AUC performance for training 0.9196060911869242\n",
            "AUC on test data =  0.883856\n",
            "AUC performance for training 0.9214789304471236\n",
            "AUC on test data =  0.8904279999999999\n",
            "AUC performance for training 0.922048194961777\n",
            "AUC on test data =  0.8895640000000001\n",
            "AUC performance for training 0.9180345038288816\n",
            "AUC on test data =  0.886316\n",
            "AUC performance for training 0.9164101824785792\n",
            "AUC on test data =  0.881608\n",
            "AUC performance for training 0.9204799533833684\n",
            "AUC on test data =  0.8840919999999999\n",
            "AUC performance for training 0.9194855239692689\n",
            "AUC on test data =  0.889104\n",
            "AUC performance for training 0.9179197376937566\n",
            "AUC on test data =  0.8847240000000001\n",
            "AUC performance for training 0.9188642435977515\n",
            "AUC on test data =  0.88278\n",
            "AUC performance for training 0.9196979672093646\n",
            "AUC on test data =  0.8845320000000001\n",
            "AUC performance for training 0.9216472663030697\n",
            "AUC on test data =  0.8862240000000001\n",
            "AUC performance for training 0.9216697142495289\n",
            "AUC on test data =  0.88418\n",
            "AUC performance for training 0.9177532608957846\n",
            "AUC on test data =  0.8822760000000001\n",
            "AUC performance for training 0.9189131483813563\n",
            "AUC on test data =  0.8818520000000001\n",
            "AUC performance for training 0.91986695560401\n",
            "AUC on test data =  0.889656\n",
            "AUC performance for training 0.9201651768988917\n",
            "AUC on test data =  0.883624\n",
            "AUC performance for training 0.9194941720264679\n",
            "AUC on test data =  0.8852760000000001\n",
            "AUC performance for training 0.9212503614410906\n",
            "AUC on test data =  0.8885919999999998\n",
            "AUC performance for training 0.9183711254556843\n",
            "AUC on test data =  0.8923719999999999\n",
            "AUC performance for training 0.918713095306954\n",
            "AUC on test data =  0.885624\n",
            "AUC performance for training 0.9194777160232023\n",
            "AUC on test data =  0.8879\n",
            "AUC performance for training 0.9217084442962675\n",
            "AUC on test data =  0.8895679999999999\n",
            "AUC performance for training 0.921533589377117\n",
            "AUC on test data =  0.8876840000000001\n",
            "AUC performance for training 0.9182439510692123\n",
            "AUC on test data =  0.8819400000000001\n",
            "AUC performance for training 0.9184019706244775\n",
            "AUC on test data =  0.8821680000000001\n",
            "AUC performance for training 0.9221124419781686\n",
            "AUC on test data =  0.88812\n",
            "AUC performance for training 0.9210934864652228\n",
            "AUC on test data =  0.8826080000000001\n",
            "AUC performance for training 0.9209683109599627\n",
            "AUC on test data =  0.888516\n",
            "AUC performance for training 0.921293326697297\n",
            "AUC on test data =  0.8884799999999999\n",
            "AUC performance for training 0.921185788459656\n",
            "AUC on test data =  0.8892719999999998\n",
            "AUC performance for training 0.9221173874109662\n",
            "AUC on test data =  0.8899239999999999\n",
            "AUC performance for training 0.9209324634450811\n",
            "AUC on test data =  0.884556\n",
            "AUC performance for training 0.9198208375179788\n",
            "AUC on test data =  0.884332\n",
            "AUC performance for training 0.918541612115683\n",
            "AUC on test data =  0.8855799999999998\n",
            "AUC performance for training 0.9188493212819607\n",
            "AUC on test data =  0.8806640000000001\n",
            "AUC performance for training 0.9214462311578909\n",
            "AUC on test data =  0.8892599999999999\n",
            "AUC performance for training 0.9193463737184985\n",
            "AUC on test data =  0.883396\n",
            "AUC performance for training 0.9214554953929693\n",
            "AUC on test data =  0.890548\n",
            "AUC performance for training 0.9192193474561577\n",
            "AUC on test data =  0.885896\n",
            "AUC performance for training 0.9216775237905817\n",
            "AUC on test data =  0.891324\n",
            "AUC performance for training 0.9182713996260373\n",
            "AUC on test data =  0.8819480000000001\n",
            "AUC performance for training 0.9196235406880696\n",
            "AUC on test data =  0.8847360000000001\n",
            "AUC performance for training 0.9207956906632229\n",
            "AUC on test data =  0.8917400000000001\n",
            "AUC performance for training 0.9204153386324867\n",
            "AUC on test data =  0.8832279999999999\n",
            "AUC performance for training 0.9178937359620272\n",
            "AUC on test data =  0.878572\n",
            "AUC performance for training 0.9211925227105816\n",
            "AUC on test data =  0.885836\n",
            "AUC performance for training 0.9217270114560361\n",
            "AUC on test data =  0.8938600000000001\n",
            "AUC performance for training 0.9193298659313625\n",
            "AUC on test data =  0.8837840000000001\n",
            "AUC performance for training 0.9201528470378739\n",
            "AUC on test data =  0.885344\n",
            "AUC performance for training 0.9205371276595574\n",
            "AUC on test data =  0.8887139999999999\n",
            "AUC performance for training 0.9193514692466149\n",
            "AUC on test data =  0.8846179999999999\n",
            "AUC performance for training 0.9180579352640247\n",
            "AUC on test data =  0.8902000000000001\n",
            "AUC performance for training 0.9202234953596441\n",
            "AUC on test data =  0.8851559999999999\n",
            "AUC performance for training 0.9212197895393539\n",
            "AUC on test data =  0.88648\n",
            "AUC performance for training 0.9165544325554774\n",
            "AUC on test data =  0.88706\n",
            "AUC performance for training 0.920917394321427\n",
            "AUC on test data =  0.8845000000000001\n",
            "AUC performance for training 0.9191260842968554\n",
            "AUC on test data =  0.883132\n",
            "AUC performance for training 0.9202841224200032\n",
            "AUC on test data =  0.8881999999999999\n",
            "AUC performance for training 0.9187290523710178\n",
            "AUC on test data =  0.887508\n",
            "AUC performance for training 0.9210478056996954\n",
            "AUC on test data =  0.889388\n",
            "AUC performance for training 0.9211894867753475\n",
            "AUC on test data =  0.8910480000000001\n",
            "AUC performance for training 0.9204047403923448\n",
            "AUC on test data =  0.886312\n",
            "AUC performance for training 0.9196994781634208\n",
            "AUC on test data =  0.8859199999999999\n",
            "AUC performance for training 0.9179811586981621\n",
            "AUC on test data =  0.8844920000000001\n",
            "AUC performance for training 0.9190989911442063\n",
            "AUC on test data =  0.8833799999999999\n",
            "AUC performance for training 0.9192375670565427\n",
            "AUC on test data =  0.884204\n",
            "AUC performance for training 0.9192214493604971\n",
            "AUC on test data =  0.8864479999999999\n",
            "AUC performance for training 0.9189484211840491\n",
            "AUC on test data =  0.883532\n",
            "AUC performance for training 0.916795629822191\n",
            "AUC on test data =  0.8877039999999999\n",
            "AUC performance for training 0.916757901830791\n",
            "AUC on test data =  0.8901679999999998\n",
            "AUC performance for training 0.919812377767698\n",
            "AUC on test data =  0.887276\n",
            "AUC performance for training 0.9207413285247056\n",
            "AUC on test data =  0.89036\n",
            "AUC performance for training 0.9196746547697054\n",
            "AUC on test data =  0.8887239999999998\n",
            "AUC performance for training 0.9209074841528342\n",
            "AUC on test data =  0.891548\n",
            "AUC performance for training 0.9198167608118307\n",
            "AUC on test data =  0.89012\n",
            "AUC performance for training 0.9210815214484461\n",
            "AUC on test data =  0.886068\n",
            "AUC performance for training 0.9159419207205818\n",
            "AUC on test data =  0.8855999999999999\n",
            "AUC performance for training 0.9189512036120266\n",
            "AUC on test data =  0.883776\n",
            "AUC performance for training 0.9210293926195859\n",
            "AUC on test data =  0.88988\n",
            "AUC performance for training 0.9174623120798311\n",
            "AUC on test data =  0.88228\n",
            "AUC performance for training 0.9185511209516957\n",
            "AUC on test data =  0.8833159999999999\n",
            "AUC performance for training 0.9159157597980095\n",
            "AUC on test data =  0.87962\n",
            "AUC performance for training 0.919376568958312\n",
            "AUC on test data =  0.8855039999999998\n",
            "AUC performance for training 0.9202871958863489\n",
            "AUC on test data =  0.890336\n",
            "AUC performance for training 0.9193495341618012\n",
            "AUC on test data =  0.885972\n",
            "AUC performance for training 0.9207056931096054\n",
            "AUC on test data =  0.8929600000000001\n",
            "AUC performance for training 0.9194772210176845\n",
            "AUC on test data =  0.885388\n",
            "AUC performance for training 0.9196991492046974\n",
            "AUC on test data =  0.8848519999999999\n",
            "AUC performance for training 0.9217808480944254\n",
            "AUC on test data =  0.8942759999999998\n",
            "AUC performance for training 0.919898038807383\n",
            "AUC on test data =  0.888684\n",
            "AUC performance for training 0.9178104772614298\n",
            "AUC on test data =  0.8838959999999999\n",
            "AUC performance for training 0.9206353748207011\n",
            "AUC on test data =  0.88776\n",
            "AUC performance for training 0.9195848673445839\n",
            "AUC on test data =  0.8901319999999999\n",
            "AUC performance for training 0.9191369356850638\n",
            "AUC on test data =  0.8866479999999999\n",
            "AUC performance for training 0.9178977066652145\n",
            "AUC on test data =  0.886536\n",
            "AUC performance for training 0.9176246354192148\n",
            "AUC on test data =  0.888844\n",
            "AUC performance for training 0.9188886895524487\n",
            "AUC on test data =  0.88812\n",
            "AUC performance for training 0.918163334622719\n",
            "AUC on test data =  0.8831000000000001\n",
            "AUC performance for training 0.9209076276386887\n",
            "AUC on test data =  0.8891039999999999\n",
            "AUC performance for training 0.9200868209231265\n",
            "AUC on test data =  0.888368\n",
            "AUC performance for training 0.9182464112246321\n",
            "AUC on test data =  0.8839719999999999\n",
            "AUC performance for training 0.9123110017012789\n",
            "AUC on test data =  0.8812559999999998\n",
            "AUC performance for training 0.9187892868774062\n",
            "AUC on test data =  0.886908\n",
            "AUC performance for training 0.9188064963354157\n",
            "AUC on test data =  0.8873119999999999\n",
            "AUC performance for training 0.9158257855793835\n",
            "AUC on test data =  0.888444\n",
            "AUC performance for training 0.9199495692553653\n",
            "AUC on test data =  0.888092\n",
            "AUC performance for training 0.9161182678539146\n",
            "AUC on test data =  0.881728\n",
            "AUC performance for training 0.9207410360343831\n",
            "AUC on test data =  0.885436\n",
            "AUC performance for training 0.9137198329617927\n",
            "AUC on test data =  0.8785279999999998\n",
            "AUC performance for training 0.9126473276458662\n",
            "AUC on test data =  0.8801120000000001\n",
            "AUC performance for training 0.9192309170652522\n",
            "AUC on test data =  0.887232\n",
            "AUC performance for training 0.9182265679840605\n",
            "AUC on test data =  0.88478\n",
            "AUC performance for training 0.9169801537199942\n",
            "AUC on test data =  0.884268\n",
            "AUC performance for training 0.9182868037578685\n",
            "AUC on test data =  0.885344\n",
            "AUC performance for training 0.9186393308438229\n",
            "AUC on test data =  0.888012\n",
            "AUC performance for training 0.9198734993747572\n",
            "AUC on test data =  0.888044\n",
            "AUC performance for training 0.9171975192800138\n",
            "AUC on test data =  0.885164\n",
            "AUC performance for training 0.9160536548689165\n",
            "AUC on test data =  0.883684\n",
            "AUC performance for training 0.9194418622579499\n",
            "AUC on test data =  0.88936\n",
            "AUC performance for training 0.9190771943027677\n",
            "AUC on test data =  0.892096\n",
            "AUC performance for training 0.9194236662452812\n",
            "AUC on test data =  0.887124\n",
            "AUC performance for training 0.9174704074574118\n",
            "AUC on test data =  0.88446\n",
            "AUC performance for training 0.917181496974028\n",
            "AUC on test data =  0.88532\n",
            "AUC performance for training 0.9189541088829545\n",
            "AUC on test data =  0.8907\n",
            "AUC performance for training 0.9179605294135196\n",
            "AUC on test data =  0.8861159999999999\n",
            "AUC performance for training 0.9202706117843807\n",
            "AUC on test data =  0.8885759999999999\n",
            "AUC performance for training 0.9190621554163559\n",
            "AUC on test data =  0.8859360000000001\n",
            "AUC performance for training 0.9177576005195962\n",
            "AUC on test data =  0.8860000000000001\n",
            "AUC performance for training 0.9174944643034368\n",
            "AUC on test data =  0.8838680000000001\n",
            "AUC performance for training 0.9170875889492032\n",
            "AUC on test data =  0.88428\n",
            "AUC performance for training 0.9172613712866561\n",
            "AUC on test data =  0.8853279999999999\n",
            "AUC performance for training 0.9178854307496727\n",
            "AUC on test data =  0.887188\n",
            "AUC performance for training 0.918043246123157\n",
            "AUC on test data =  0.8908400000000001\n",
            "AUC performance for training 0.918992971434163\n",
            "AUC on test data =  0.8886999999999998\n",
            "AUC performance for training 0.9171788823928967\n",
            "AUC on test data =  0.8877200000000001\n",
            "AUC performance for training 0.9174110397309303\n",
            "AUC on test data =  0.884568\n",
            "AUC performance for training 0.9203187549452986\n",
            "AUC on test data =  0.8908800000000001\n",
            "AUC performance for training 0.9166767537423738\n",
            "AUC on test data =  0.881312\n",
            "AUC performance for training 0.917633064978921\n",
            "AUC on test data =  0.8871120000000001\n",
            "AUC performance for training 0.918353700235506\n",
            "AUC on test data =  0.8866639999999999\n",
            "AUC performance for training 0.9177870088251707\n",
            "AUC on test data =  0.8861840000000001\n",
            "AUC performance for training 0.9152994348549989\n",
            "AUC on test data =  0.8810159999999998\n",
            "AUC performance for training 0.9198131304405195\n",
            "AUC on test data =  0.89242\n",
            "AUC performance for training 0.9206461176262744\n",
            "AUC on test data =  0.889912\n",
            "AUC performance for training 0.9198826454014907\n",
            "AUC on test data =  0.891084\n",
            "AUC performance for training 0.9184289628869613\n",
            "AUC on test data =  0.885752\n",
            "AUC performance for training 0.9170552192645971\n",
            "AUC on test data =  0.88508\n",
            "AUC performance for training 0.91857668169294\n",
            "AUC on test data =  0.8870480000000001\n",
            "AUC performance for training 0.9181258085041967\n",
            "AUC on test data =  0.887432\n",
            "AUC performance for training 0.9168764217104644\n",
            "AUC on test data =  0.8863759999999998\n",
            "AUC performance for training 0.9167729866059138\n",
            "AUC on test data =  0.8832719999999998\n",
            "AUC performance for training 0.9159447148907376\n",
            "AUC on test data =  0.8834\n",
            "AUC performance for training 0.9176444468950803\n",
            "AUC on test data =  0.8865639999999999\n",
            "AUC performance for training 0.9184074356491989\n",
            "AUC on test data =  0.8878599999999999\n",
            "AUC performance for training 0.9178222103853507\n",
            "AUC on test data =  0.88618\n",
            "AUC performance for training 0.9173837069519544\n",
            "AUC on test data =  0.8880719999999999\n",
            "AUC performance for training 0.9149384112750977\n",
            "AUC on test data =  0.8811519999999999\n",
            "AUC performance for training 0.9190230070536298\n",
            "AUC on test data =  0.8894199999999999\n",
            "AUC performance for training 0.9168813621390354\n",
            "AUC on test data =  0.885864\n",
            "AUC performance for training 0.915319161089325\n",
            "AUC on test data =  0.882216\n",
            "AUC performance for training 0.9174919735943754\n",
            "AUC on test data =  0.8853159999999999\n",
            "AUC performance for training 0.9162135282532653\n",
            "AUC on test data =  0.884228\n",
            "AUC performance for training 0.9179158920846099\n",
            "AUC on test data =  0.8871679999999998\n",
            "AUC performance for training 0.9162683599707365\n",
            "AUC on test data =  0.8833399999999999\n",
            "AUC performance for training 0.9127991057409899\n",
            "AUC on test data =  0.8857519999999999\n",
            "AUC performance for training 0.9136824431394834\n",
            "AUC on test data =  0.881068\n",
            "AUC performance for training 0.9185864507781797\n",
            "AUC on test data =  0.89315\n",
            "AUC performance for training 0.9182152599594575\n",
            "AUC on test data =  0.8900759999999999\n",
            "AUC performance for training 0.916614539454273\n",
            "AUC on test data =  0.8868199999999999\n",
            "AUC performance for training 0.9179298877855948\n",
            "AUC on test data =  0.8902439999999999\n",
            "AUC performance for training 0.9184209956401369\n",
            "AUC on test data =  0.8902800000000001\n",
            "AUC performance for training 0.9186080723883713\n",
            "AUC on test data =  0.888632\n",
            "AUC performance for training 0.9183150909557286\n",
            "AUC on test data =  0.8857359999999999\n",
            "AUC performance for training 0.9193570379864728\n",
            "AUC on test data =  0.8909759999999999\n",
            "AUC performance for training 0.9168150372127413\n",
            "AUC on test data =  0.887984\n",
            "AUC performance for training 0.9170655674512788\n",
            "AUC on test data =  0.888712\n",
            "AUC performance for training 0.917942208625177\n",
            "AUC on test data =  0.887948\n",
            "AUC performance for training 0.9151814380881814\n",
            "AUC on test data =  0.880904\n",
            "AUC performance for training 0.9164061834822677\n",
            "AUC on test data =  0.88701\n",
            "AUC performance for training 0.917525113474733\n",
            "AUC on test data =  0.8863000000000001\n",
            "AUC performance for training 0.9125896911926705\n",
            "AUC on test data =  0.8823799999999999\n",
            "AUC performance for training 0.9137677734130452\n",
            "AUC on test data =  0.8814\n",
            "AUC performance for training 0.9178897196035424\n",
            "AUC on test data =  0.8876679999999999\n",
            "AUC performance for training 0.9175903540376956\n",
            "AUC on test data =  0.887972\n",
            "AUC performance for training 0.9161393407790438\n",
            "AUC on test data =  0.885236\n",
            "AUC performance for training 0.9156619516457924\n",
            "AUC on test data =  0.8845640000000001\n",
            "AUC performance for training 0.9174281726679889\n",
            "AUC on test data =  0.888392\n",
            "AUC performance for training 0.9166777873999483\n",
            "AUC on test data =  0.8859559999999999\n",
            "AUC performance for training 0.9162153003368838\n",
            "AUC on test data =  0.88694\n",
            "AUC performance for training 0.918290906243696\n",
            "AUC on test data =  0.890764\n",
            "AUC performance for training 0.9168932928266106\n",
            "AUC on test data =  0.883696\n",
            "AUC performance for training 0.9184531900742998\n",
            "AUC on test data =  0.88826\n",
            "AUC performance for training 0.9151371132299474\n",
            "AUC on test data =  0.8863719999999999\n",
            "AUC performance for training 0.9147815191403099\n",
            "AUC on test data =  0.884004\n",
            "AUC performance for training 0.9170576466019866\n",
            "AUC on test data =  0.886584\n",
            "AUC performance for training 0.9159210528283938\n",
            "AUC on test data =  0.884836\n",
            "AUC performance for training 0.9154729191170964\n",
            "AUC on test data =  0.89018\n",
            "AUC performance for training 0.9179119769176975\n",
            "AUC on test data =  0.8923399999999999\n",
            "AUC performance for training 0.9162869515268829\n",
            "AUC on test data =  0.8888879999999999\n",
            "AUC performance for training 0.9165808252542264\n",
            "AUC on test data =  0.887668\n",
            "AUC performance for training 0.916568244905557\n",
            "AUC on test data =  0.8851959999999999\n",
            "AUC performance for training 0.9193139178316602\n",
            "AUC on test data =  0.892532\n",
            "AUC performance for training 0.9127169745312591\n",
            "AUC on test data =  0.886508\n",
            "AUC performance for training 0.9166055556702446\n",
            "AUC on test data =  0.891372\n",
            "AUC performance for training 0.9134795994939222\n",
            "AUC on test data =  0.8823519999999999\n",
            "AUC performance for training 0.9157374334915523\n",
            "AUC on test data =  0.8863\n",
            "AUC performance for training 0.9130824028338512\n",
            "AUC on test data =  0.881176\n",
            "AUC performance for training 0.9177597464796614\n",
            "AUC on test data =  0.889312\n",
            "AUC performance for training 0.9173767107931374\n",
            "AUC on test data =  0.890172\n",
            "AUC performance for training 0.915520544130612\n",
            "AUC on test data =  0.8837320000000001\n",
            "AUC performance for training 0.9097840178323618\n",
            "AUC on test data =  0.8804760000000001\n",
            "AUC performance for training 0.9151165708069781\n",
            "AUC on test data =  0.88576\n",
            "AUC performance for training 0.9124327572325299\n",
            "AUC on test data =  0.884908\n",
            "AUC performance for training 0.9121871707373583\n",
            "AUC on test data =  0.8833200000000001\n",
            "AUC performance for training 0.9162330375075184\n",
            "AUC on test data =  0.8904719999999999\n",
            "AUC performance for training 0.9154275498464114\n",
            "AUC on test data =  0.886452\n",
            "AUC performance for training 0.9116244155449686\n",
            "AUC on test data =  0.8811519999999999\n",
            "AUC performance for training 0.9132512785950054\n",
            "AUC on test data =  0.8875200000000001\n",
            "AUC performance for training 0.9154955833867482\n",
            "AUC on test data =  0.886232\n",
            "AUC performance for training 0.9167499073593495\n",
            "AUC on test data =  0.88878\n",
            "AUC performance for training 0.9169211210954754\n",
            "AUC on test data =  0.887624\n",
            "AUC performance for training 0.915627395399496\n",
            "AUC on test data =  0.886524\n",
            "AUC performance for training 0.9169387406809749\n",
            "AUC on test data =  0.8891959999999999\n",
            "AUC performance for training 0.9088291689028375\n",
            "AUC on test data =  0.884916\n",
            "AUC performance for training 0.9136066220101754\n",
            "AUC on test data =  0.8841680000000001\n",
            "AUC performance for training 0.9140894583492578\n",
            "AUC on test data =  0.8832960000000001\n",
            "AUC performance for training 0.9157838623155328\n",
            "AUC on test data =  0.888012\n",
            "AUC performance for training 0.9182167001464907\n",
            "AUC on test data =  0.892916\n",
            "AUC performance for training 0.9080160046619729\n",
            "AUC on test data =  0.8885599999999999\n",
            "AUC performance for training 0.9105619687205958\n",
            "AUC on test data =  0.881988\n",
            "AUC performance for training 0.9116559933096304\n",
            "AUC on test data =  0.889596\n",
            "AUC performance for training 0.915284865712601\n",
            "AUC on test data =  0.8920119999999999\n",
            "AUC performance for training 0.9088915754840355\n",
            "AUC on test data =  0.879684\n",
            "AUC performance for training 0.9150117162598739\n",
            "AUC on test data =  0.8906880000000001\n",
            "AUC performance for training 0.9134714798800275\n",
            "AUC on test data =  0.884816\n",
            "AUC performance for training 0.914775575128386\n",
            "AUC on test data =  0.890748\n",
            "AUC performance for training 0.9150333157902019\n",
            "AUC on test data =  0.8889\n",
            "AUC performance for training 0.9149262072756071\n",
            "AUC on test data =  0.889456\n",
            "AUC performance for training 0.9131672113078005\n",
            "AUC on test data =  0.885332\n",
            "AUC performance for training 0.9107142060194476\n",
            "AUC on test data =  0.88514\n",
            "AUC performance for training 0.9120572704159698\n",
            "AUC on test data =  0.88324\n",
            "AUC performance for training 0.916289621333822\n",
            "AUC on test data =  0.891788\n",
            "AUC performance for training 0.9136136933573902\n",
            "AUC on test data =  0.885992\n",
            "AUC performance for training 0.9156998021762779\n",
            "AUC on test data =  0.891024\n",
            "AUC performance for training 0.914325624200705\n",
            "AUC on test data =  0.884164\n",
            "AUC performance for training 0.9121201359756936\n",
            "AUC on test data =  0.882822\n",
            "AUC performance for training 0.9130614965481381\n",
            "AUC on test data =  0.88396\n",
            "AUC performance for training 0.9132546035177963\n",
            "AUC on test data =  0.8838679999999999\n",
            "AUC performance for training 0.9130208949469075\n",
            "AUC on test data =  0.8848079999999999\n",
            "AUC performance for training 0.9106711380327495\n",
            "AUC on test data =  0.88242\n",
            "AUC performance for training 0.9153510496239283\n",
            "AUC on test data =  0.88642\n",
            "AUC performance for training 0.9122789539170757\n",
            "AUC on test data =  0.88108\n",
            "AUC performance for training 0.9144321231907219\n",
            "AUC on test data =  0.8861239999999999\n",
            "       Done!           ##########################################               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ePt7fpX_A5Pi",
        "colab_type": "code",
        "outputId": "b7dd355d-ece7-4ffd-8ef8-32acddb8abc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "      model.eval()\n",
        "      auc=[]\n",
        "     \n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "\n",
        "          pred=output.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "          \n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #                         \n",
        "      AUC_training=np.mean(auc)\n",
        "      print('AUC on test data = ',AUC_training)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC on test data =  0.9066879999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zsxzjJNMTBDb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}